<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta name="generator"
    content="HTML Tidy for HTML5 (experimental) for Windows https://github.com/w3c/tidy-html5/tree/c63cc39" />
    <title>裴炤</title>
    <!-- META TAGS -->
    
    <!-- CSS FILES -->
    <link href="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/css/bootstrap.min.css" />
    <link rel="stylesheet" href="css/bootstrap-responsive.css" type="text/css" />
    <script src="https://cdn.staticfile.org/jquery/2.1.1/jquery.min.js"></script>
    <script src="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <link href="css/fontawesome.css" rel="stylesheet" type="text/css" />
    <link href="css/slick.css" rel="stylesheet" type="text/css" />
    <link href="css/style.css" rel="stylesheet" type="text/css" />
  </head>
  <body>
  <progress value="0" id="eskimo-progress-bar"></progress> 
  <!-- 菜单栏 -->
  <div class="container">
    <img src="images/Peterlogo.png" /> 
  <!--菜单栏-->
  <nav class="navbar navbar-default" role="navigation">

        <ul class="nav navbar-nav">
        <li>
          <a href="index.html">个人简介</a>
        </li>
		 <li>
          <a href="lab.html">实验室</a>
        </li>
        <li>
          <a href="Result.html">研究成果</a>
        </li>
		<li>
          <a href="Course.html">授课</a>
        </li>
        <li>
          <a href="Contact.html">招生信息</a>
        </li>
        
       
 
      </ul>
  </nav>

  <!-- 论文成果 -->
  <h2>论文成果</h2>
  <div>
    <ul class="list-group">
      <li class="list-group-item small">[1] Zhao Pei, Xiaoning Qi, Yanning Zhang, Miao Ma and Yee-Hong Yang, 
      <a href="https://pdf.sciencedirectassets.com/272206/1-s2.0-S0031320319X00059/1-s2.0-S0031320319301712/main.pdf?X-Amz-Security-Token=AgoJb3JpZ2luX2VjELD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQDGwuPMbSi9yFJxnFZBqCQ6ta%2BTqBWbMm3iNu6R%2BUzJ8wIgXfcLULiamuaoc%2FeQcnAtaCPvpWpxhCXA9nzWW8viIfsq4wMIif%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARACGgwwNTkwMDM1NDY4NjUiDOQBrxRg74qLUqveayq3A3Xffi5xK76mRf4tCLnnZudn9EXXSLQk7HdxtNISV%2FeT22dIuKV0aJ7kKxG%2FqA3ODoZXR2IZJMttjZDZy1fykm6nn3FCrklF2gNg9%2BitTOEaHcvXA08V%2FlvYPdSJ6V9ndkkGCjAwh5ZbiX1HsgDg4NAU%2FfZwrSmlGg7XFEac%2BlGRWgzCozm3T%2B%2BGA5WTmcjYlrBzpgjB2%2Ftn1IjIDxwIUCLfKLKIpphUqvMmbhLShpa2jEFU1hzHcbxYp%2Fo2xco3bkQ0E6VYfQjrdupth2kK%2FJACw0JPJq03xVKkgEsuR%2FfN94qOapxqciAJfNqchBF7rxqyepAN4repoIyhx2jlqhnYmKqS%2Bd8JEk28fM9JiuIdSJaALyArosXmderzSebC7Or9wzc4sJ9%2B0W28FLjtBvptsuYTiQILpEMuBbPtUYcnUB4Q2CliCE7Ixsq44mwn%2BW0WsdOVS%2Bo8VVtdEBUDVcv4PpljFaAW608qH70mCN205NCHRLfAH8JWS174KLs1k4NZBloquJ8N5UfB%2FniWQ1KYmob1EftHRb%2FFn2zu%2BfCsEkgiKl5HcLYRCRFJW9BxqyVcxtTH8UAwsJi87AU6tAGlfN5jD5HpX9qubjjErZPKAow6snmO%2BvUgqNu%2B38%2FkZ0uIvV69fgmbjm9zjVjMzCluS2itMuTNwuYMriRqkvjHBaz%2FzO%2BrFD5qWolPuBI9kcNPeDwJxs8SwdcL%2BWs4k64fH3bBvxYIgfNPLMfwL3K3i%2F0hGcM54KimtTFtVlYKtRAMZ3PW%2FXU0oqIVAnAUoQ8szami4x5w%2FiPsyutdm7nBk1GyY1%2F5h2GjlzkP7pF6gkVgIks%3D&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20190928T074606Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTYY3VMJTNJ%2F20190928%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Signature=108bb90b590a251f92a6d3a8b5f884858ccb954add52d29527f39e6c47d8e46a&amp;hash=a7b681b990385ff77b5572f79eed6cb9b78a05e8d42c6ab56b8a81edce897be5&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S0031320319301712&amp;tid=spdf-aa02a3cc-bb0b-4bfa-8354-21a5021ebff8&amp;sid=327f0d838084a342155b8884c83a24603f97gxrqb&amp;type=client">
      “Human trajectory prediction in crowded scene using social-affinity Long Short-Term Memory,”</a> 
      <strong>Pattern Recognition (PR)</strong>, Vol.93, pp.273-282, 201. 
      <strong style="color:#78d2ec">(IF=5.898)</strong></li>
      <li class="list-group-item small">[2]Zhao Pei, Li Huang, Yanning Zhang, Miao Ma, Yali Peng and Yeehong Yang, 
      <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8630923">“Focus Measure for Synthetic Aperture Imaging
      Using a Deep Convolutional Network,”</a> 
      <strong>IEEE Access</strong>, Vol.7, No.12, pp2169-3536, 2019. 
      <strong style="color:#78d2ec">(IF=4.098)</strong></li>
      <li class="list-group-item small">[3] Zhao Pei, Yawen Li, Miao Ma, Jun Li, Chengcai Leng, Xiaoqiang Zhang and Yanning Zhang, 
      <a href="https://www.mdpi.com/1424-8220/19/3/607/htm">“Occluded-Object 3D Reconstruction Using Camera Array Synthetic
      Aperture Imaging,”</a> 
      <strong>Sensors</strong>, Vol.19, No.3, 2019. 
      <strong style="color:#78d2ec">(IF=3.031)</strong></li>
	  
      <li class="list-group-item small">[4] Yuqian Kuang, Min Guo, Yali Peng and Zhao Pei, 
      <a href="https://link.springer.com/article/10.1007/s11042-019-07862-0">“Learner posture recognition via a fusing model based
      on improved SILTP and LDP 2019,”</a> 
      <strong>Multimedia Tools and Applications</strong>, pp.1-14, 2019.</li>
	  
      <li class="list-group-item small">[5] Zhao Pei, Hang Xu, Yanning Zhang, Min Guo and Yee-Hong Yang, 
      <a href="https://www.mdpi.com/2079-9292/8/10/1088">“Face Recognition via Deep Learning Using Data Augmentation Based on
      Orthogonal,”</a> 
      <strong>Electronics</strong>, Vol.8, No.10, 2019.</li>
	  
      <li class="list-group-item small">[6] Zhao Pei, Xida Chen and Yee-Hong Yang, 
      <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7583662">“All-in-focus Synthetic Aperture Imaging Using
      Image Matting,”</a> 
      <strong>IEEE Transactions on Circuits and Systems For Video Technology(TCSVT)</strong>,Vol.28, No.2, pp288-301, 2018. 
      <strong style="color:#78d2ec">(IF=4.046)</strong></li>
	  
      <li class="list-group-item small">[7] Zhao Pei, Miaomiao Pan, Kang Liao, Miao Ma and Chengcai Leng, “Predict Student’s
      Seating Distribution Based on Social Affinity,” In Proceedings of the International Conference on Smart Multimedia, Toulon,
      France. Aug. 2018.</li>
	  
      <li class="list-group-item small">[8]Jingcheng Ke, Yali Peng, Shigang Liu, Jun Li and Zhao Pei, 
      <a href="https://www.tandfonline.com/doi/full/10.1080/09500340.2017.1380854">“Face recognition based on symmetrical virtual
      image and original training image,”</a> Journal of Modern Optics, Vol.65, No.4, pp367-380, 2018. 
      <strong style="color:#78d2ec">(IF=4.046)</strong></li>
	  
	  
	  
      <li class="list-group-item small">[9]Chengcai Leng, Hai Zhang, Bo Li, Guorong Cai, Zhao Pei and Li He, 
      <a href="https://ieeexplore.ieee.org/document/8584423">“Local feature descriptor for image matching: A Survey,”</a> IEEE Access, Vol.7, pp6424-6434, 2018. 
      <strong style="color:#78d2ec">(IF=4.098)</strong></li>
	  
	  
	  
	  
      <li class="list-group-item small">[10] Zhao Pei, Haixing Shang, Yi Su, Miao Ma and Yali Peng, “Convolutional Neural Networks
      for Class Attendance,” In Proceedings of the 13th International Conference on Natural Computation, Fuzzy System and Knowledge
      Discovery(FSKD 17), Guilin, China. July 2017.</li>
	  
      <li class="list-group-item small">[11] Zhao Pei, Yanning Zhang, Xida Chen and Yee-Hong Yang, 
      <a href="https://www.sciencedirect.com/science/article/pii/S0031320312002841">“Synthetic Aperture Imaging Using Pixel
      Labeling via Energy Minimization,”</a> 
      <strong>Pattern Recognition (PR)</strong>, Vol.46, No.1, pp.174-187, Jan. 2013. 
      <strong style="color:#78d2ec">(IF=5.898)</strong></li>
	  
      <li class="list-group-item small">[12] Zhao Pei, Yanning Zhang, Tao Yang, Xiuwei Zhang and Yee-Hong Yang, 
      <a href="http://www.saiip-vision.org/papers/PR.pdf">“A Novel Multi-Object Detection Method in Complex Scene Using Synthetic
      Aperture Imaging,”</a> 
      <strong>Pattern Recognition (PR)</strong>, Vol.45, No.4, pp.1637–1658, Apr. 2012. 
      <strong style="color:#78d2ec">(IF=5.898)</strong></li>
	  
      <li class="list-group-item small">[13] Zhao Pei, Yanning Zhang, Tao Yang, and Xida Chen, “A Novel Method for Detecting
      Occluded Object by Multiple Camera Arrays,”&lt;&gt; In Proceedings of the 9th International Conference on Fuzzy Systems and
      Knowledge Discovery(FSKD 12), pp.1692–1696, Chongqing, China, May 2012.</li>
	  
      <li class="list-group-item small">[14] Zhao Pei, Yanning Zhang, Tao Yang, and Xida Chen, “Synthetic Aperture Image Quality
      Assessment Based on Camera Array: Measures and Their Performance,” In Proceedings of the 9th International Conference on
      Fuzzy Systems and Knowledge Discovery(FSKD 12), pp.1981–1985, Chongqing, China, May 2012.</li>
	  
      <li class="list-group-item small">[15] Zhao Pei, Yanning Zhang, Tao Yang, Xiuwei Zhang and Yee-Hong Yang, 
      <a href="https://www.sciencedirect.com/science/article/pii/S0031320311004067">“A novel multi-object detection method in
      complex scene using synthetic aperture imaging,”</a> 
      <strong>Pattern Recognition (PR)</strong>, Vol.45, No.4, pp. 1637-1658, 2012. 
      <strong style="color:#78d2ec">(IF=5.898)</strong></li>
	  
      <li class="list-group-item small">[16] Zhao Pei, Yanning Zhang, Zenggang Lin, Heng Zhou and Hui Wang, “A Method of Image
      Processing Algorithm Evaluation Based on Orthogonal Experimental Design,” In Proceedings of the Fifth International
      Conference on Image and Graphics(ICIG 09), pp.629–633, Xian, China, Sept. 2009.</li>
    </ul>
  </div>
  <hr />
  <!-- 专利成果 -->
  <h2>专利成果</h2>
  <div class="">
    <h6>授权发明专利</h6>
    <ul class="list-group">
      <li class="list-group-item small">[1]裴炤;张艳宁;陈希达;马苗;孙莉;张秀伟. 基于相机阵列合成孔径成像的遮挡背景估计方法.
      中国，中华人民共和国国家知识产权局，发明专利，专利授权号：ZL201610043867.4.</li>
      <li class="list-group-item small">[2]裴炤;陈希达;马苗;刘侍刚;彭亚丽. 基于自动目标提取的全聚焦合成孔径成像方法.
      中国，中华人民共和国国家知识产权局，发明专利，专利授权号：ZL201610044313.6.</li>
      <li class="list-group-item small">[3]裴炤;张艳宁;彭亚丽;马苗;尚海星;苏艺. 基于多人脸数据采集策略和深度学习的课堂考勤方法.
      中国，中华人民共和国国家知识产权局，发明专利，专利授权号：ZL201610504632.0.</li>
      <li class="list-group-item small">[4]裴炤;张艳宁;孙莉;马苗;汪西莉;郭敏. 基于双相机阵列的合成孔径目标多视角成像方法.
      中国，中华人民共和国国家知识产权局，发明专利，专利授权号：ZL201610044284.3.</li>
      <li class="list-group-item small">[5]马苗;刘琳;武杰;陈昱莅;裴炤. 图像分类卷积神经网络结构的构建方法. 中国，中华人民共和国国家知识产权局，发明专利，专利授权号：ZL201710106457.4.</li>
      <li class="list-group-item small">[6]武杰;张冰云;马苗;裴炤;陈昱莅;杨楷芳. 基于子空间划分的合成孔径雷达影像变化检测方法.
      中国，中华人民共和国国家知识产权局，发明专利，专利授权号：ZL201710429994.2.</li>
      <li class="list-group-item small">[7]马苗;朱青青;郑雪;孙莉;裴炤;郭敏. 对人体面部微笑表情深度卷积神经网络的检测方法.
      中国，中华人民共和国国家知识产权局，发明专利，专利授权号：ZL201610089191.2.</li>
      <li class="list-group-item small">[8]马苗;陈祖雪;郭敏;陈昱莅;裴炤. 深度信息静态手势分割方法. 中国，中华人民共和国国家知识产权局，发明专利，专利授权号：ZL201610187599.3.</li>
    </ul>
    <h6>受理发明专利</h6>
    <ul class="list-group">
      <li class="list-group-item small">[1]郭敏;郑平;马苗;裴炤. 表面肌电信号手势识别方法. 中国，中华人民共和国国家知识产权局，发明专利，专利受理号：CN201810552616.8.</li>
      <li class="list-group-item small">[2]裴炤;徐航;马苗;彭亚丽;武杰;曹文飞. 基于正交实验分析的深度学习人脸图像扩充方法. 中国，中华人民共和国国家知识产权局，发明专利，专利受理号：
      CN201810346925.X.</li>
      <li class="list-group-item small">[3]裴炤;张艳宁;齐晓宁;马苗;汪西莉;徐航. 基于社会亲和力长短期记忆网络模型的拥挤场景行人轨迹预测方法.
      中国，中华人民共和国国家知识产权局，发明专利，专利受理号：CN201810294015.1.</li>
      <li class="list-group-item small">[4]裴炤;张艳宁;沈乐棋;马苗;郭敏. 基于卷积神经网络的合成孔径聚焦成像深度评估方法. 中国，中华人民共和国国家知识产权局，发明专利，专利受理号：
      CN201810139139.2.</li>
      <li class="list-group-item small">[5]裴炤;沈乐棋;张艳宁;马苗;郭敏. 基于像素标记和合成孔径成像的遮挡目标三维重建方法. 中国，中华人民共和国国家知识产权局，发明专利，专利受理号：
      CN201810139192.2.</li>
      <li class="list-group-item small">[6]裴炤;潘苗苗;马苗;彭亚丽;郭敏. 基于学生社交关系模型的课堂座位分布预测方法. 中国，中华人民共和国国家知识产权局，发明专利，专利受理号：
      CN201710898390.2.</li>
      <li class="list-group-item small">[7]马苗;刘琳;武杰;陈昱莅;裴炤. 图像分类卷积神经网络结构的构建方法. 中国，中华人民共和国国家知识产权局，发明专利，专利受理号： CN201710106457.4.</li>
      <li class="list-group-item small">[8] 裴炤;廖康;张艳宁;马苗;郭敏. 基于中心投影的学生课堂社交网络自动构建方法. 中国，中华人民共和国国家知识产权局，发明专利，专利受理号：
      CN201710303995.2.</li>
    </ul>
  </div>
  <hr />
  <!--软著 
            <h2>软件登记</h2>
            <div class="eskimo-tabs-content tab-content">
                <table class="table table-striped">
                    <tr><th>著作人</th><th>软件名称</th><th>登记号</th>
                    <tr><td>裴炤, 徐航等</td><td>基于c++和python的人脸识别软件</td><td>2018SR311533</td>
                    <tr><td>裴炤, 彭其阳等</td><td>基于VGG的课堂考勤系统V1.0</td><td>2018SR844448</td>
                    <tr><td>裴炤, 李雅文等</td><td>合成孔径遮挡目标3D重建软件V1.0</td><td>2018SR575</td>
                    <tr><td>裴炤, 齐晓宁等</td><td>目标行动轨迹预测软件V1.0</td><td>C2018SR552041</td>
                </table>

            </div>--></div>
  <!-- JS FILES -->
  <script src="js/jquery-3.3.1.min.js"></script> 
  <script src="js/bootstrap.min.js"></script> 
  <script src="js/salvattore.min.js"></script> 
  <script src="js/panel.js"></script> 
  <script src="js/reading-position-indicator.js"></script> 
  <script src="js/featherlight.js"></script> 
  <script src="js/ajax-contact-form.js"></script> 
  <script src="js/custom.js"></script></body>
</html>
